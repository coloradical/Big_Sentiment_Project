{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests.auth\n",
    "from requests_oauthlib import OAuth1\n",
    "import oauth2 as oauth\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credentials from local source:\n",
    "reader = csv.reader(open(\"/Users/mchifala/Desktop/ATLS_5412/Credentials.csv\"))\n",
    "credentials = {}\n",
    "for line in reader:\n",
    "    credentials[line[0]] = line[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Reddit credentials:\n",
    "def getRedditHeaders():\n",
    "    reddit_id = credentials['reddit_id']\n",
    "    reddit_secret = credentials['reddit_secret']\n",
    "    reddit_username = credentials['reddit_username']\n",
    "    reddit_password = credentials['reddit_password']\n",
    "    reddit_user_agent = credentials['reddit_user_agent']\n",
    "\n",
    "    reddit_auth = requests.auth.HTTPBasicAuth(reddit_id, reddit_secret)\n",
    "    reddit_post_data = {'grant_type': 'password', 'username': reddit_username, 'password': reddit_password}\n",
    "    reddit_token_headers = {'User-Agent': reddit_user_agent}\n",
    "    r = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth= reddit_auth, data=reddit_post_data, headers=reddit_token_headers)\n",
    "    #print(r.json())\n",
    "\n",
    "    reddit_token = r.json()['token_type'] + ' ' + r.json()['access_token']\n",
    "    \n",
    "    # Return header dictionary\n",
    "    return {\"Authorization\": reddit_token, \"User-Agent\": reddit_user_agent, 'Content-Type': 'application/json'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests_oauthlib.oauth1_auth.OAuth1 at 0x11172cb70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Twitter credentials:\n",
    "def getTwitterAuth():\n",
    "    twitter_key = credentials['twitter_key']\n",
    "    twitter_secret =  credentials['twitter_secret']\n",
    "    twitter_token = credentials['twitter_token']\n",
    "    twitter_secret_token = credentials['twitter_secret_token']\n",
    "    \n",
    "    #Return authorization object\n",
    "    return OAuth1(twitter_key, twitter_secret, twitter_token, twitter_secret_token)\n",
    "\n",
    "getTwitterAuth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available Twitter trends:\n",
    "twitter_auth = getTwitterAuth()\n",
    "r = requests.get('https://api.twitter.com/1.1/trends/available.json', auth = twitter_auth)\n",
    "#print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2972, 3369, 3444, 3534, 4118, 8676, 8775, 9807, 12723]\n"
     ]
    }
   ],
   "source": [
    "# Extract the location ID codes for trends:\n",
    "world_codes = []\n",
    "for i in range(0,len(r.json())):\n",
    "    world_codes.append(r.json()[i]['woeid'])\n",
    "\n",
    "test_codes = world_codes[0:10]\n",
    "print(test_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#4Mar',\n",
       " '#ActúaTec2019',\n",
       " '#Bournemouth',\n",
       " '#BuenLunes',\n",
       " '#CafeTacvba',\n",
       " '#Carnaval',\n",
       " '#DíaDeLaFamilia',\n",
       " '#EcuadorEsCarnaval',\n",
       " '#FelizLunes',\n",
       " '#FinalAmarAMuerte',\n",
       " '#GoodVibesConCafé',\n",
       " '#GordonBanks',\n",
       " '#GuaidoDeRegreso',\n",
       " '#IMFC',\n",
       " '#IWD2019',\n",
       " '#J9CL2019',\n",
       " '#LaHuelgaFeministaVa',\n",
       " '#MasterChefChile',\n",
       " '#MondayMotivation',\n",
       " '#NAW2019',\n",
       " '#RIPKeithFlint',\n",
       " '#RIPLukePerry',\n",
       " '#SoompiAwards',\n",
       " '#SuperLunes',\n",
       " '#TeJuroQueTeAmo',\n",
       " '#TeamBTS',\n",
       " '#TristeTurno',\n",
       " '#TwitterBestFandom',\n",
       " '#VamosJuntosALaCalle',\n",
       " '#VolvioCartuchos',\n",
       " '#afcb',\n",
       " '#avfc',\n",
       " '#elcaminodelajepes',\n",
       " '#guerra',\n",
       " '#intrusos2019',\n",
       " '#serfieraesunorgullo',\n",
       " '#swfc',\n",
       " '#الوصل_النصر',\n",
       " 'AMLO',\n",
       " 'Absolutely',\n",
       " 'Alberta',\n",
       " 'Almada',\n",
       " 'Anthony Ríos',\n",
       " 'Argentina',\n",
       " 'Barranquilla',\n",
       " 'Bienvenido Presidente',\n",
       " 'Birmingham',\n",
       " 'Brad Blair',\n",
       " 'Charlottetown',\n",
       " 'Cheers',\n",
       " 'Dylan McKay',\n",
       " 'EEUU',\n",
       " 'Estados Unidos',\n",
       " 'Everton',\n",
       " 'FARC',\n",
       " 'Fine Gael',\n",
       " 'GRACIAS ELENCO AAM',\n",
       " 'Gordon Banks OBE',\n",
       " 'Guanajuato',\n",
       " 'John Candy',\n",
       " 'Keith Flint',\n",
       " 'Klopp',\n",
       " 'Leicester',\n",
       " 'Liverpool',\n",
       " 'London',\n",
       " 'Luke Perry',\n",
       " 'Maiquetía',\n",
       " 'Mark Durkan',\n",
       " 'Miriam Germán',\n",
       " 'Omega',\n",
       " 'Pachuca',\n",
       " 'Pizarro',\n",
       " 'Portsmouth',\n",
       " 'Procurador',\n",
       " 'Prodigy',\n",
       " 'RENAP',\n",
       " 'RIP Keith',\n",
       " 'RIP Keith Flint',\n",
       " 'Ricardo Méndez Ruiz',\n",
       " 'SDLP',\n",
       " 'Santrich',\n",
       " 'Siii',\n",
       " 'Sonora',\n",
       " 'Southampton',\n",
       " 'TE AMO JULIANTINA',\n",
       " 'The Prodigy',\n",
       " 'Vzla',\n",
       " 'Wos y Dani',\n",
       " 'gracias barbarena',\n",
       " 'mazatlán'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "#الوصل_النصر\n",
      "Dylan McKay\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Dylan McKay\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "#IWD2019\n",
      "Charlottetown\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Dylan McKay\n",
      "#IMFC\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Dylan McKay\n",
      "Alberta\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Brad Blair\n",
      "Dylan McKay\n",
      "Luke Perry\n",
      "#MondayMotivation\n",
      "Keith Flint\n",
      "John Candy\n",
      "Liverpool\n",
      "London\n",
      "#avfc\n",
      "Birmingham\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Keith Flint\n",
      "Liverpool\n",
      "#afcb\n",
      "#Bournemouth\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Liverpool\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "The Prodigy\n",
      "#RIPKeithFlint\n",
      "Keith Flint\n",
      "#MondayMotivation\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "#GordonBanks\n",
      "RIP Keith Flint\n",
      "#NAW2019\n",
      "Liverpool\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "Keith Flint\n",
      "Prodigy\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Leicester\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "Everton\n",
      "Klopp\n",
      "Liverpool\n",
      "Absolutely\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "RIP Keith Flint\n",
      "The Prodigy\n",
      "Southampton\n",
      "Portsmouth\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "#swfc\n",
      "Cheers\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "#GordonBanks\n",
      "Keith Flint\n",
      "RIP Keith\n",
      "Gordon Banks OBE\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "#RIPKeithFlint\n",
      "Liverpool\n",
      "Luke Perry\n",
      "#RIPLukePerry\n",
      "Keith Flint\n",
      "Luke Perry\n",
      "Mark Durkan\n",
      "SDLP\n",
      "Fine Gael\n",
      "Miriam Germán\n",
      "Omega\n",
      "Anthony Ríos\n",
      "Procurador\n",
      "RENAP\n",
      "#FelizLunes\n",
      "Ricardo Méndez Ruiz\n",
      "Keith Flint\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "#TristeTurno\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "AMLO\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#FelizLunes\n",
      "#Carnaval\n",
      "mazatlán\n",
      "Sonora\n",
      "#TeJuroQueTeAmo\n",
      "#TwitterBestFandom\n",
      "#SoompiAwards\n",
      "#J9CL2019\n",
      "#FinalAmarAMuerte\n",
      "gracias barbarena\n",
      "GRACIAS ELENCO AAM\n",
      "TE AMO JULIANTINA\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "#DíaDeLaFamilia\n",
      "#serfieraesunorgullo\n",
      "Guanajuato\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#TwitterBestFandom\n",
      "#SoompiAwards\n",
      "#TeamBTS\n",
      "#guerra\n",
      "Siii\n",
      "Pachuca\n",
      "Pizarro\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#FelizLunes\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "#ActúaTec2019\n",
      "Keith Flint\n",
      "#BuenLunes\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "Luke Perry\n",
      "#FelizLunes\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "#FinalAmarAMuerte\n",
      "#TwitterBestFandom\n",
      "Estados Unidos\n",
      "Luke Perry\n",
      "#FelizLunes\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "#FelizLunes\n",
      "Luke Perry\n",
      "#CafeTacvba\n",
      "#GoodVibesConCafé\n",
      "Argentina\n",
      "Luke Perry\n",
      "Wos y Dani\n",
      "#VolvioCartuchos\n",
      "#LaHuelgaFeministaVa\n",
      "#MasterChefChile\n",
      "#SuperLunes\n",
      "#FelizLunes\n",
      "#LaHuelgaFeministaVa\n",
      "Luke Perry\n",
      "#intrusos2019\n",
      "Maiquetía\n",
      "Luke Perry\n",
      "#LaHuelgaFeministaVa\n",
      "#intrusos2019\n",
      "Maiquetía\n",
      "#elcaminodelajepes\n",
      "Luke Perry\n",
      "Maiquetía\n",
      "#FelizLunes\n",
      "#elcaminodelajepes\n",
      "Luke Perry\n",
      "Maiquetía\n",
      "#FelizLunes\n",
      "#elcaminodelajepes\n",
      "FARC\n",
      "Santrich\n",
      "Luke Perry\n",
      "Barranquilla\n",
      "#elcaminodelajepes\n",
      "Luke Perry\n",
      "Maiquetía\n",
      "Maiquetía\n",
      "#FelizLunes\n",
      "#EcuadorEsCarnaval\n",
      "Almada\n",
      "Maiquetía\n",
      "#FelizLunes\n",
      "#VamosJuntosALaCalle\n",
      "#4Mar\n",
      "Maiquetía\n",
      "#4Mar\n",
      "#GuaidoDeRegreso\n",
      "#VamosJuntosALaCalle\n",
      "Maiquetía\n",
      "#4Mar\n",
      "#GuaidoDeRegreso\n",
      "#VamosJuntosALaCalle\n",
      "#4Mar\n",
      "Maiquetía\n",
      "#GuaidoDeRegreso\n",
      "#VamosJuntosALaCalle\n",
      "Maiquetía\n",
      "#4Mar\n",
      "#GuaidoDeRegreso\n",
      "Bienvenido Presidente\n",
      "Vzla\n",
      "EEUU\n",
      "Maiquetía\n",
      "#4Mar\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-928dff369506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworld_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.twitter.com/1.1/trends/place.json?id='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trends'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtopics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trends'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#Search each location ID for its specific trends:\n",
    "topics = []\n",
    "for code in world_codes:\n",
    "    r2 = requests.get('https://api.twitter.com/1.1/trends/place.json?id='+str(code), auth = twitter_auth)\n",
    "    for i in range(0,len(r2.json()[0])):\n",
    "        print(r2.json()[0]['trends'][i]['name'])\n",
    "        topics.append((r2.json()[0]['trends'][i]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Calls: 509.0\n",
      "Time to Reset: 536\n",
      "Remaining Calls: 508.0\n",
      "Time to Reset: 536\n",
      "Remaining Calls: 507.0\n",
      "Time to Reset: 536\n",
      "Remaining Calls: 506.0\n",
      "Time to Reset: 535\n",
      "Remaining Calls: 505.0\n",
      "Time to Reset: 535\n",
      "Remaining Calls: 504.0\n",
      "Time to Reset: 535\n",
      "Remaining Calls: 503.0\n",
      "Time to Reset: 534\n",
      "Remaining Calls: 502.0\n",
      "Time to Reset: 534\n",
      "Remaining Calls: 501.0\n",
      "Time to Reset: 534\n",
      "Remaining Calls: 500.0\n",
      "Time to Reset: 534\n",
      "Remaining Calls: 499.0\n",
      "Time to Reset: 534\n",
      "Remaining Calls: 498.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 497.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 496.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 495.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 494.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 493.0\n",
      "Time to Reset: 533\n",
      "Remaining Calls: 492.0\n",
      "Time to Reset: 532\n",
      "Remaining Calls: 491.0\n",
      "Time to Reset: 532\n",
      "Remaining Calls: 490.0\n",
      "Time to Reset: 532\n",
      "Remaining Calls: 489.0\n",
      "Time to Reset: 532\n",
      "Remaining Calls: 488.0\n",
      "Time to Reset: 531\n",
      "Remaining Calls: 487.0\n",
      "Time to Reset: 531\n",
      "Remaining Calls: 486.0\n",
      "Time to Reset: 531\n",
      "Remaining Calls: 485.0\n",
      "Time to Reset: 531\n",
      "Remaining Calls: 484.0\n",
      "Time to Reset: 530\n",
      "Remaining Calls: 483.0\n",
      "Time to Reset: 530\n",
      "Remaining Calls: 482.0\n",
      "Time to Reset: 530\n",
      "Remaining Calls: 481.0\n",
      "Time to Reset: 530\n",
      "Remaining Calls: 480.0\n",
      "Time to Reset: 529\n",
      "Remaining Calls: 479.0\n",
      "Time to Reset: 529\n",
      "Remaining Calls: 478.0\n",
      "Time to Reset: 528\n",
      "Remaining Calls: 477.0\n",
      "Time to Reset: 528\n",
      "Remaining Calls: 476.0\n",
      "Time to Reset: 528\n",
      "Remaining Calls: 475.0\n",
      "Time to Reset: 527\n",
      "Remaining Calls: 474.0\n",
      "Time to Reset: 527\n",
      "Remaining Calls: 473.0\n",
      "Time to Reset: 527\n",
      "Remaining Calls: 472.0\n",
      "Time to Reset: 526\n",
      "Remaining Calls: 471.0\n",
      "Time to Reset: 526\n",
      "Remaining Calls: 470.0\n",
      "Time to Reset: 526\n",
      "Remaining Calls: 469.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 468.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 467.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 466.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 465.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 464.0\n",
      "Time to Reset: 525\n",
      "Remaining Calls: 463.0\n",
      "Time to Reset: 524\n",
      "Remaining Calls: 462.0\n",
      "Time to Reset: 524\n",
      "Remaining Calls: 461.0\n",
      "Time to Reset: 524\n",
      "Remaining Calls: 460.0\n",
      "Time to Reset: 523\n",
      "Remaining Calls: 459.0\n",
      "Time to Reset: 523\n",
      "Remaining Calls: 458.0\n",
      "Time to Reset: 523\n",
      "Remaining Calls: 457.0\n",
      "Time to Reset: 523\n",
      "Remaining Calls: 456.0\n",
      "Time to Reset: 523\n",
      "Remaining Calls: 455.0\n",
      "Time to Reset: 522\n",
      "Remaining Calls: 454.0\n",
      "Time to Reset: 522\n",
      "Remaining Calls: 453.0\n",
      "Time to Reset: 522\n",
      "Remaining Calls: 452.0\n",
      "Time to Reset: 521\n",
      "Remaining Calls: 451.0\n",
      "Time to Reset: 521\n",
      "Remaining Calls: 450.0\n",
      "Time to Reset: 521\n",
      "Remaining Calls: 449.0\n",
      "Time to Reset: 520\n",
      "Remaining Calls: 448.0\n",
      "Time to Reset: 520\n",
      "Remaining Calls: 447.0\n",
      "Time to Reset: 520\n",
      "Remaining Calls: 446.0\n",
      "Time to Reset: 520\n",
      "Remaining Calls: 445.0\n",
      "Time to Reset: 519\n",
      "Remaining Calls: 444.0\n",
      "Time to Reset: 519\n",
      "Remaining Calls: 443.0\n",
      "Time to Reset: 519\n",
      "Remaining Calls: 442.0\n",
      "Time to Reset: 519\n",
      "Remaining Calls: 441.0\n",
      "Time to Reset: 519\n",
      "Remaining Calls: 440.0\n",
      "Time to Reset: 518\n",
      "Remaining Calls: 439.0\n",
      "Time to Reset: 518\n",
      "Remaining Calls: 438.0\n",
      "Time to Reset: 517\n",
      "Remaining Calls: 437.0\n",
      "Time to Reset: 517\n",
      "Remaining Calls: 436.0\n",
      "Time to Reset: 517\n",
      "Remaining Calls: 435.0\n",
      "Time to Reset: 516\n",
      "Remaining Calls: 434.0\n",
      "Time to Reset: 516\n",
      "Remaining Calls: 433.0\n",
      "Time to Reset: 516\n",
      "Remaining Calls: 432.0\n",
      "Time to Reset: 515\n",
      "Remaining Calls: 431.0\n",
      "Time to Reset: 515\n",
      "Remaining Calls: 430.0\n",
      "Time to Reset: 515\n",
      "Remaining Calls: 429.0\n",
      "Time to Reset: 515\n",
      "Remaining Calls: 428.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 427.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 426.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 425.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 424.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 423.0\n",
      "Time to Reset: 514\n",
      "Remaining Calls: 422.0\n",
      "Time to Reset: 513\n",
      "Remaining Calls: 421.0\n",
      "Time to Reset: 513\n",
      "Remaining Calls: 420.0\n",
      "Time to Reset: 513\n"
     ]
    }
   ],
   "source": [
    "# Make Reddit queries for trends and upload to Elasticsearch:\n",
    "reddit_headers = getRedditHeaders()\n",
    "elastic_headers = {'Content-Type':'application/json'}\n",
    "for query in set(topics):\n",
    "    index = 'test_03_04_19_part2'\n",
    "    r_get = requests.get('https://oauth.reddit.com/r/all/search?q='+query+'&t=day&limit=25', headers = reddit_headers)\n",
    "    r_get.headers['content-type']\n",
    "    list = r_get.json()['data']['children']\n",
    "    print(\"Remaining Calls:\", r_get.headers['x-ratelimit-remaining'])\n",
    "    print(\"Time to Reset:\", r_get.headers['x-ratelimit-reset'])\n",
    "    data = []\n",
    "    fields_to_keep = ['id','title', 'author', 'score', 'subreddit', 'num_comments', 'num_crossposts', 'created_utc']\n",
    "    for value in list:\n",
    "        temp = {k: value['data'][k] for k in fields_to_keep}\n",
    "        temp.update({'hashtag': query})\n",
    "        data.append({'index': {\"_index\": index, '_type': '_doc', '_id': 'r_'+ temp['id'] }})\n",
    "        del temp['id']\n",
    "        data.append(temp)\n",
    "        \n",
    "    if data:\n",
    "        data_to_post = '\\n'.join(json.dumps(d) for d in data) \n",
    "        #print(data_to_post)\n",
    "        #print(\"\\n New topic! \\n\")\n",
    "        r_post = requests.post('http://localhost:9200/'+index+'/_bulk', headers = elastic_headers, data=data_to_post+'\\n')\n",
    "        #print(r_post.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"index\": {\"_index\": \"test5\", \"_type\": \"type1\", \"_id\": \"1\"}}\n",
      "{\"field1\": \"value1\"}\n",
      "{\"delete\": {\"_index\": \"test5\", \"_type\": \"type1\", \"_id\": \"2\"}}\n",
      "{\"create\": {\"_index\": \"test5\", \"_type\": \"type1\", \"_id\": \"3\"}}\n",
      "{\"field1\": \"value3\"}\n",
      "{\"update\": {\"_id\": \"1\", \"_type\": \"type1\", \"_index\": \"test5\"}}\n",
      "{\"doc\": {\"field2\": \"value2\"}}\n"
     ]
    }
   ],
   "source": [
    "# This is a working example: make sure the indexes match\n",
    "import json\n",
    "data = [\n",
    "    { \"index\" : { \"_index\" : \"test5\", \"_type\" : \"type1\", \"_id\" : \"1\" } },\n",
    "    { \"field1\" : \"value1\" },\n",
    "    { \"delete\" : { \"_index\" : \"test5\", \"_type\" : \"type1\", \"_id\" : \"2\" }, },\n",
    "    { \"create\" : { \"_index\" : \"test5\", \"_type\" : \"type1\", \"_id\" : \"3\" }, },\n",
    "    { \"field1\" : \"value3\" },\n",
    "    { \"update\" : {\"_id\" : \"1\", \"_type\" : \"type1\", \"_index\" : \"test5\"} },\n",
    "    { \"doc\" : {\"field2\" : \"value2\"} }\n",
    "]\n",
    "\n",
    "data_to_post = '\\n'.join(json.dumps(d) for d in data)\n",
    "print(data_to_post)\n",
    "#r = requests.post('http://localhost:9200/test5/_bulk', headers = headers, data=data_to_post + '\\n')\n",
    "#print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communicating with Elastic Search:\n",
    "#r = requests.get('http://localhost:9200/twitter/_doc/TQqw02gBSrHX7MwTUvS-', headers = {'User-agent': 'mchifala'})\n",
    "requests.post('http://34.73.60.209:9200/hi_yash/_doc/',  json = {\"user\" : \"kimchy\",\n",
    "    \"post_date\" : \"2019-01-28T14:12:12\",\n",
    "    \"message\" : \"Hi Yash\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
